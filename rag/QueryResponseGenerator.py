import os
from dotenv import load_dotenv
from langchain_openai import AzureChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from rag.AzureSearchContentRetriever import AzureSearchContentRetriever

# Load environment variables from a .env file
load_dotenv(dotenv_path="../.env")

class QueryResponseGenerator:
    """
    Class to generate responses to user queries using Azure OpenAI and Azure Cognitive Search.
    
    The class interacts with Azure OpenAI to generate language-based responses based on
    the user's query, leveraging Azure Cognitive Search to provide relevant document content.
    
    Attributes:
    ----------
    model_name : str
        The name of the GPT model deployed in Azure OpenAI.
    deployment : str
        The deployment name for the GPT model in Azure OpenAI.
    api_key : str
        API key for accessing Azure OpenAI services.
    endpoint : str
        The endpoint for accessing the Azure OpenAI service.
    version : str
        API version for Azure OpenAI.
    temperature : float
        The temperature setting for the model to control response randomness.
    llm : AzureChatOpenAI
        Instance of AzureChatOpenAI for language generation.
    retriever : AzureSearchContentRetriever
        Instance of AzureSearchContentRetriever to fetch relevant documents.
    
    Methods:
    -------
    _initialize_llm_instance() -> AzureChatOpenAI:
        Initializes the AzureChatOpenAI instance using environment configurations.
    
    get_chat_query_response(query: str) -> str:
        Takes a user query, retrieves relevant document contexts using Azure Search,
        and generates a response using Azure OpenAI GPT-4.
    """

    def __init__(self):
        """
        Initializes the QueryResponseGenerator instance with environment variables
        and sets up both the language model (AzureChatOpenAI) and the document retriever.
        """
        # Retrieve environment variables for Azure OpenAI
        self.model_name = os.getenv("AZURE_OPENAI_GPT4_MODEL")
        self.deployment = os.getenv("AZURE_OPENAI_GPT4_DEPLOYMENT")
        self.api_key = os.getenv("AZURE_OPENAI_GPT4_KEY")
        self.endpoint = os.getenv("AZURE_OPENAI_GPT4_ENDPOINT")
        self.version = os.getenv("AZURE_OPENAI_GPT4_VERSION")
        self.temperature = 0.2  # Controls the randomness of the responses
        
        # Initialize the AzureChatOpenAI instance
        self.llm = self._initialize_llm_instance()
        
        # Initialize the AzureSearchContentRetriever for document search
        self.retriever = AzureSearchContentRetriever()

    def _initialize_llm_instance(self) -> AzureChatOpenAI:
        """
        Initializes an instance of AzureChatOpenAI using the specified configuration.
        
        Returns:
        -------
        AzureChatOpenAI
            An instance of the language model to generate responses.
        """
        return AzureChatOpenAI(
            model=self.model_name,
            azure_deployment=self.deployment,
            openai_api_version=self.version,
            openai_api_key=self.api_key,
            azure_endpoint=self.endpoint,
            temperature=self.temperature
        )

    def get_chat_query_response(self, query: str) -> str:
        """
        Generates a response to a user query by first retrieving relevant documents
        and then using Azure OpenAI GPT-4 to generate an intelligent answer.
        
        Parameters:
        ----------
        query : str
            The user's input question to be answered.
        
        Returns:
        -------
        str
            The response generated by Azure OpenAI based on the query and the context.
        """
        # Retrieve relevant documents using the document retriever
        retrieved_documents = self.retriever.retrieve_searched_documents(query)
        
        # If no documents are found, return a no-results message
        if not retrieved_documents:
            return "No relevant documents found."

        # Define a prompt template to guide the GPT model
        template = (
            '''
            You are a highly intelligent question-answer bot. You are designed to provide comprehensive and informative responses 
            based on the context of the provided documents. You should answer the user's questions and offer guidance 
            as an experienced HR professional would, considering policies, procedures, and best practices mentioned in the handbook.
            If the question is not directly related to the context or you do not have enough information to answer it accurately, 
            respond with 'I'm not sure how to answer that based on the provided information.' or 'I don't have the information to answer this question.' 
            Be concise with your answer and complete the sentences. Do not leave anything incomplete.

            Context: {context}

            Question: {query}
            '''
        )
        # Create a prompt template for conversation
        prompt_template = ChatPromptTemplate.from_template(template)

        # Format the prompt with the retrieved document context and the user query
        formatted_prompt = prompt_template.format_prompt(context=retrieved_documents, query=query)

        # Convert the formatted prompt to message format
        messages = formatted_prompt.to_messages()

        # Get the response from AzureChatOpenAI using the prompt messages
        get_llm_response = self.llm(messages)

        # Extract and return the content from the language model's response
        response_content = get_llm_response.content
        return response_content


# Example usage
if __name__ == "__main__":
    # Create an instance of QueryResponseGenerator
    content_generation_object = QueryResponseGenerator()

    # Query to retrieve documents and generate a response
    response = content_generation_object.get_chat_query_response("When does the AppleCare Protection Plan's coverage for defects begin?")
    
    # Output the response
    print("Response is:\n", response)
